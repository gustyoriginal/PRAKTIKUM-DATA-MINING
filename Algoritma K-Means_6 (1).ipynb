{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eeb69e6-ab80-4956-b6d0-9f39823715ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.6.1-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.15.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.6.1-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "Downloading scipy-1.15.3-cp312-cp312-win_amd64.whl (41.0 MB)\n",
      "   ---------------------------------------- 0.0/41.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/41.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/41.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.8/41.0 MB 2.8 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 1.3/41.0 MB 2.9 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 2.1/41.0 MB 3.3 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 2.9/41.0 MB 3.2 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 3.9/41.0 MB 3.7 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 5.5/41.0 MB 4.3 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 6.6/41.0 MB 4.4 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 7.3/41.0 MB 4.4 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 8.4/41.0 MB 4.4 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 9.4/41.0 MB 4.5 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 11.3/41.0 MB 4.9 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 12.8/41.0 MB 5.1 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 14.7/41.0 MB 5.4 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 16.0/41.0 MB 5.5 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 17.8/41.0 MB 5.7 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 18.9/41.0 MB 5.7 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 19.9/41.0 MB 5.6 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 21.8/41.0 MB 5.8 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 23.6/41.0 MB 6.0 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 24.9/41.0 MB 6.0 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 26.0/41.0 MB 6.0 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 27.3/41.0 MB 6.0 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 28.6/41.0 MB 6.0 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 30.1/41.0 MB 6.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 32.2/41.0 MB 6.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 33.8/41.0 MB 6.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 35.4/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 36.7/41.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 38.0/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 39.1/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.4/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.0/41.0 MB 2.7 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "Successfully installed scikit-learn-1.6.1 scipy-1.15.3 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4e42cf6-8756-447c-b8ae-fc797472ce4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Cluster 1\n",
      " - @ppnnooxx @AlfnGnrs @aldibawazier_ lah postingan lain beda konteks lah pea, selain baper, fans mu gak bisa ngecerna tulisan ya alias minim literasi....makanya stop bahas sejarah biar gak baper dan stress, btw Selamat liverpool udah menang 20 trofi liga Inggris\n",
      " - @ppnnooxx @AlfnGnrs @aldibawazier_ nah coba lo baca lagi postingan aldi, ada bawa bawa MU? soalnya setau aku format liga inggris emang berubah sejak tahun 92.... Kebanyakan bahas sejarah jadinya baperan njir\n",
      " - @notfakboyyy @liskiataumi @idextratime @footballontnt musim ini enggak sih\n",
      "dari 12 tim yang masih main di kompetisi eropa 4 dari liga inggris\n",
      "dan musim depan ada kemungkinan inggris punya 6 wakil di liga champions kalau MU/Spurs juara europa\n",
      " - @idextratime @footballontnt predikat liga terbaik sih masih bisa diperdebatkan. tapi yang pasti liga inggris ini liga terseru untuk diikuti. apalagi jam tayangnya bersahabat untuk asia. kalau nonton liga lain gak tau kenapa bawaannya bosen ditonton.\n",
      " - @TohhirRadin @LaunchSatelite @liskiataumi @idextratime @footballontnt Prestasi juara liga champion atau Europa, kalo dilihat banyak tim liga Inggris ko yang juara dibanding liga2 lain contoh Spain yang juara champions paling madrid barca liga Inggris nothingham sama Aston aja pernah\n",
      "\n",
      " Cluster 2\n",
      " - RT @The_RedsIndo: Gary Neville menegaskan bahwa Liverpool adalah klub terbesar di Inggris.\n",
      "\n",
      "Neville: \"Liverpool memiliki lebih banyak Piala…\n",
      " - RT @The_RedsIndo: Gary Neville menegaskan bahwa Liverpool adalah klub terbesar di Inggris.\n",
      "\n",
      "Neville: \"Liverpool memiliki lebih banyak Piala…\n",
      " - RT @The_RedsIndo: Gary Neville menegaskan bahwa Liverpool adalah klub terbesar di Inggris.\n",
      "\n",
      "Neville: \"Liverpool memiliki lebih banyak Piala…\n",
      " - RT @The_RedsIndo: Gary Neville menegaskan bahwa Liverpool adalah klub terbesar di Inggris.\n",
      "\n",
      "Neville: \"Liverpool memiliki lebih banyak Piala…\n",
      " - RT @The_RedsIndo: Gary Neville menegaskan bahwa Liverpool adalah klub terbesar di Inggris.\n",
      "\n",
      "Neville: \"Liverpool memiliki lebih banyak Piala…\n",
      "\n",
      " Cluster 3\n",
      " - RT @The_RedsIndo: Daftar kapten Liverpool saat memenangi gelar Liga Inggris:\n",
      "\n",
      "🏴󠁧󠁢󠁳󠁣󠁴󠁿 Alex Raisbeck (1900-01, 1905-06)\n",
      "🏴󠁧󠁢󠁳󠁣󠁴󠁿 Donald Macki…\n",
      " - RT @lupa_mancing: Mentari menyapa juara liga inggris. Scouse is not england. Kepalkan tanganmu kawand✊✊. Sampai menang.\n",
      "#YNWA #aaauuuwww ht…\n",
      " - RT @theflankerID: LIVERPOOL JUARA PREMIER LEAGUE\n",
      "\n",
      "- Memutus dominasi Manchester City\n",
      "- Slot mampu juara di musim perdana, lebih dulu dari A…\n",
      " - Liverpool Kunci Juara Liga Inggris usai Hajar Tottenham Hotspur 5-1\n",
      "\n",
      "Cakeeeppp\n",
      " - RT @The_RedsIndo: Daftar kapten Liverpool saat memenangi gelar Liga Inggris:\n",
      "\n",
      "🏴󠁧󠁢󠁳󠁣󠁴󠁿 Alex Raisbeck (1900-01, 1905-06)\n",
      "🏴󠁧󠁢󠁳󠁣󠁴󠁿 Donald Macki…\n",
      "\n",
      " Cluster 4\n",
      " - @The_RedsIndo Kan emang 20.. yg blg 2 siapa? Klo d format EPL mmg 2.. klo total juara Liga utama Inggris y 20.. gmn dah? Kan mmg sama dgn MU 20 juara.. biasa itu.. dulu pas MU masih 7 gelar trus nyamain jd 18 apakah seberisik ini jg?\n",
      " - RT @nagromsew: @utdfocusid Lho ini ngakunya skrg punya 20 gelar? Ga 13 EPL?\n",
      "\n",
      "Adu bacot sama fans Liverpool :\n",
      "MU punya 13 gelar EPL, Liverpo…\n",
      " - RT @txtdrkeylie: mau 13 epl kek, 2 epl kek. itungan secara keseluruhannya ttp GELAR LIGA INGGRIS. fans emyu jgn berisik dah kocak, mending…\n",
      " - RT @utdfocusid: Pejamkan mata lalu nikmati detik-detik terakhir kita sebagai penguasa Liga Inggris dengan 20 gelar juaranya.\n",
      "\n",
      "Sebentar lagi…\n",
      " - RT @txtdrkeylie: mau 13 epl kek, 2 epl kek. itungan secara keseluruhannya ttp GELAR LIGA INGGRIS. fans emyu jgn berisik dah kocak, mending…\n",
      "\n",
      " Cluster 5\n",
      " - @pretendto068 @The_RedsIndo Arsenal secara tropi aja terbanyak ketiga setelah Liverpool &amp; MU, dilihat dari tropi liga Inggris juga Arsenal nomor 3, jadi tim mana yg ngga layak?\n",
      " - @DwiPrasetyaSan1 @Seiiraz @LaunchSatelite @liskiataumi @idextratime @footballontnt Hadiahnya juga banyakan liga inggris.apa lagi udah jelas Uefa dan para wasit...nya Kebanyakan bepihak ke tim spanyol\n",
      " - @Seiiraz @TohhirRadin @LaunchSatelite @liskiataumi @idextratime @footballontnt Liga spanyol pemilik terbanyak gelar juara eropa. Bukan cuman UCL. UEL juga, bahkan sejak 2006, final UCL/UEL aja kalau tim spanyol vs inggris aja menang tim spanyol\n",
      " - @utdfocusid Belegug, ngitung jumlah titel juara liga Inggris selalu dari perubahan nama liga. ...siga bolon wae😅\n",
      " - @idextratime @footballontnt Liga lain mainya bisa 70 %  bisa sambil leha lehe bisa tetap menang.kalau di inggris main kaya gitu bisa  kalah lawan tim papan bawah  SEKALIPUN.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "\n",
    "\n",
    "df = pd.read_csv('C:/kelompok1_22230011.csv')\n",
    "tweets = df['Isi Tweet'].dropna().tolist()\n",
    "\n",
    "\n",
    "factory = StopWordRemoverFactory()\n",
    "stop_words = set(factory.get_stop_words())\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)       \n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)    \n",
    "    text = text.lower()\n",
    "    tokens = text.split()\n",
    "    return ' '.join([w for w in tokens if w not in stop_words])\n",
    "\n",
    "tweets_cleaned = [preprocess(t) for t in tweets]\n",
    "\n",
    "# Vektorisasi\n",
    "vectorizer = TfidfVectorizer(max_df=0.8, min_df=2)\n",
    "X = vectorizer.fit_transform(tweets_cleaned)\n",
    "\n",
    "# Clustering\n",
    "k = 5\n",
    "model = KMeans(n_clusters=k, random_state=42)\n",
    "model.fit(X)\n",
    "\n",
    "\n",
    "for i in range(k):\n",
    "    print(f\"\\n Cluster {i+1}\")\n",
    "    indices = [j for j, label in enumerate(model.labels_) if label == i]\n",
    "    for idx in indices[:5]:  \n",
    "        print(f\" - {tweets[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b956af6a-0bb7-4d9c-8a1d-2b1f8cef5b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
